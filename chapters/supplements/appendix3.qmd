---
title: Untitled
format:
  dissertation-template-typst: default
---

```{r}
#| include: false
#| echo: false

library(tidyverse)
library(lavaan)
library(flextable)
library(patchwork)
library(ggsci)
library(pwr)
library(faux)

## Chapter 4 ----
### Analysis objects ----

load("staged_results/chapter4/study2_staged_results.RData")
load("staged_results/chapter4/pilot_staged_results.RData")
load("staged_results/chapter4/pooled_staged_results.RData")
load("staged_results/chapter4/study1_staged_results.RData")

load("staged_results/chapter4/supp/pilot/supp_section2.Rdata")
load("staged_results/chapter4/supp/study1/supp_section2.Rdata")
load("staged_results/chapter4/supp/study2/supp_section2.Rdata")
load("staged_results/chapter4/supp/pilot/mod_fit_flanker.RData")
load("staged_results/chapter4/supp/study1/ssp_fit.RData")
load("staged_results/chapter4/supp/study2/ssp_fit.RData")
load("staged_results/chapter4/supp/pilot/DDM_objects.Rdata")
load("staged_results/chapter4/supp/pilot/hddm_recovery_plots.RData")

power_linear      <- read_csv("staged_results/chapter4/power_linear_model.csv") %>% mutate(power = round(power, 0))
power_mixed       <- read_csv("staged_results/chapter4/power_mixed_model.csv") %>% mutate(power = round(power, 0))

## Knitting options ----
knitr::opts_chunk$set(
  echo = F,
  fig.align = "center",
  fig.pos = "!t", 
  out.extra = "",
  fig.show = "asis",
  message = FALSE,
  tab.topcaption = T,
  warning = FALSE
)

# set up flextable for tables
set_flextable_defaults(
  font.family = "Times", 
  font.size = 10,
  font.color = "black",
  line_spacing = 1,
  padding.bottom = 1, 
  padding.top = 1,
  padding.left = 1,
  padding.right = 1
)
```

```{=typst}
#show: article.with(
  chapter: "Supplementary materials",
  chtitle: "Appendix 3"
)
```

```{=typst}
#pagebreak(to: "odd")
```

# Appendix 3 - Chapter 4

## Section 1. Descriptions of exploratory measures

Current state, poverty exposure, impulsivity, future orientation, and depressive symptoms were collected in all three studies.
Attentional style was collected in Study 2 only.

### Current state 
We assessed state anxiety during the experiment using the state subscale of the State-Trait Anxiety Inventory [STAI-S\; @spielberger_1999]. 
The STAI-S contains 20 short items measuring current anxiety (e.g., "I feel tense"). 
Participants rated each item on a scale of 1 (not at all) to 4 (very much so). 
An overall state anxiety variable was computed by averaging across the 20 unweighted items.

In addition, participants answered five questions relating to specific states: "Are you currently sick?" (rated as yes or no); "Have you eaten a full meal today?" (rated as yes or no); "How hungry do you feel right now?" (rated from 1 (not at all) to 5 (very hungry)); "How well did you sleep last night?" (rated from 1 (very poorly) to 5 (very well)); "How rested or refreshed did you feel when you woke up this morning?" (rated from 1 (not at all) to 5 (very rested)). We computed an overall sleep deprivation composite by standardizing and averaging across the two unweighted sleep-related items.

### Poverty exposure 
Participants' perceived level of resource scarcity before age 13 was measured using seven items (e.g., "Your family had enough money to afford the kind of home you all needed"). 
Participants rated each item on a scale from 1 (never true) to 5 (very often true). 
Scores for the first six items were reverse coded so that higher scores indicated more perceived resource scarcity. 
The items were averaged together to create an unweighted composite scale.

In addition, we measured several indicators of objective SES before age 13. 
First, participants separately indicated the highest education of their mother and father on an 8-point scale: 'some high school', 'GED', 'high school diploma', 'some college but no college degree', associate's  degree', 'bachelor's degree', 'master's  degree', or 'doctoral or lab degree'. 
The mother and father education level were averaged to create an overall unweighted parental education composite. 
Participants also indicated their family's household income before age 13 on a 6-point scale: 'less than \$ 25k/year', '\$25k - \$49k/year, '\$50 - \$74k/year', '\$75 - \$99k/year', '\$100 - \$149k/year', 'more than \$150k/year'. 
Scores were reverse coded so that higher scores indicated higher levels of poverty.

We created a composite score of poverty exposure before age 13 by averaging together the standardized scores of perceived level of resource scarcity, overall parental education, and household income.

### Impulsivity 
We assessed impulsivity with the Motor Impulsivity subscale of the Barrett Impulsivity Scale [BIS short form\; @patton_1995; @spinella_2007]. 
The Motor Impulsivity subscale of the BIS consists of five items (e.g., "I do things without thinking").
We did not include the Non-planning subscale because it overlapped substantially with the Future Orientation Scale described below. 
In addition, we did not include the Attention impulsivity subscale because it included items which we deemed to be mostly irrelevant for our target population (e.g., "I 'squirm' at plays or lectures"). 
We changed the original 4-point rating scale (rarely/never to almost always) to a 5-point rating scale ranging from 1 (never true) to 5 (very often true). 
An overall impulsivity variable was computed by averaging the five unweighted items.

### Future Orientation
We assessed future orientation with an adapted version of the Future Orientation Scale [FOS\; @steinberg_2009]. 
The original scale consists of 15 sets of opposing items separated by "BUT" (e.g., "Some people like to plan things out one step at a time BUT other people like to jump right into things without planning them out beforehand"). 
Participants first choose the item that best matches their general preference, and then indicate whether the statement is "really true" or "somewhat true". 
We adapted this format in a couple of ways. 
First, we converted the two statements per item to a single statement by picking the statements in the original right-hand column. 
Second, we adapted the 15 statements from a third-person to a first-person format. 
These changes were made in an attempt to reduce the cognitive load of the items. 
We worried that people with less formal education or who were sitting in a noisier environment would struggle with the length of the original items. 

In addition, item 8 of the original scale ("[...] other people would rather spend their money right away on something fun than save it for a rainy day") was changed to "I'd rather spend money right away than save it for a rainy day" (i.e., dropping the phrase "on something fun") to make it more general with regard to the thing that money is spent on. 
For people from adversity, spending money right now instead of saving it for the future might often be born out of necessity (e.g., having just enough money for food and shelter; being in debt) instead of a failure to delay gratification. 
Finally, the rating scale was adapted from the original 4-point scale (ranging from really true for the left-hand statement to really true for the right-hand statement) to a 5-point scale ranging from 1 (never true) to 5 (very often true).
An overall future orientation variable was computed by averaging the 15 unweighted items.

### Depressive symptoms 
We assessed depressive symptoms during the past week using the Center for Epidemiologic Studies Depression Scale [CESD\; @radloff_1977]. 
The scale consists of 20 items (e.g., "I do things without thinking"). 
Participants rate each item on a scale of 1 (rarely or none of the time (less than 1 day)) to 4 (most or all of the time (5-7 days)). 
An overall depression variable was computed by averaging the 20 unweighted items.

### Attentional style
We measured attentional style using the Attentional Style Questionnaire [ASQ\; @calster_2018].
The ASQ measures self-reported attentional style, with seven items asking about the participant's propensity for internally oriented attention (e.g., "During an activity, unrelated mmental images and thoughts come to my mind") and seven items about externally oriented attention (e.g., "I am easily drawn to new stimuli (for example, voices of people passing by, as sound in the house, ...) that are not relevant to a task I am doing"). 
Where necessary, items were recoded in such a way that they reflected *distractibility* by internal and external stimuli, respectively, with higher scores reflecting a higher degree of distractibility.
We computed unweighted averages separately for internally oriented attention and externally oriented attention.

## Section 2. Exploratory analyses

### Consistency in unpredictability measures

**Pilot.** The EFA yielded five factors based on parallel analysis (see Table A3.1).
Based on their contents, we labelled these factors (1) Daily unpredictability; (2) Household routine; (3) Spatial unpredictability; (4) Chaos/clutter; (5) Social unpredictability.

::: {.landscape}

```{r}
#| tab.id: tableA3.1
#| results: markup
pilot_efa_table |> 
  flextable::compose(
    i = 1, j = 1,
    as_paragraph(as_b("Table A3.1. "), "Exploratory factor analysis on unpredictability items in the Pilot (Part 1)."),
    part = "header"
  ) |>
  delete_rows(i = 38:67, part = "body") |> 
  border_remove() |> 
  border(i = 2, border.top = fp_border_default(), part = "header") |>  
  border(i = 2, border.bottom = fp_border_default(), part = "header") |> 
  border(i = 37, border.bottom = fp_border_default(), part = "body") |>  
  padding(
    i = 1:37,
    j = 1:6,
    padding.top = 3,
    padding.bottom = 3,
    part = "body"
  ) |> 
  padding(
    i = 1:2,
    j = 1:6,
    padding.top = 3,
    padding.bottom = 3,
    part = "header"
  ) |> 
  autofit()
```

:::

::: {.landscape}

```{r}
#| tab.id: tableA3.2
#| results: markup
pilot_efa_table |> 
  flextable::compose(
    i = 1, j = 1,
    as_paragraph(as_b("Table A3.2. "), "Exploratory factor analysis on unpredictability items in the Pilot (Part 2)."),
    part = "header"
  ) |>
  delete_rows(i = 1:37, part = "body") |> 
  border_remove() |> 
  border(i = 2, border.top = fp_border_default(), part = "header") |>  
  border(i = 2, border.bottom = fp_border_default(), part = "header") |> 
  border(i = 30, border.bottom = fp_border_default(), part = "body") |>  
  padding(
    i = 1:30,
    j = 1:6,
    padding.top = 3,
    padding.bottom = 3,
    part = "body"
  ) |> 
  padding(
    i = 1:2,
    j = 1:6,
    padding.top = 3,
    padding.bottom = 3,
    part = "header"
  ) |> 
  autofit()
```

:::

**Study 1.** Similar to the Pilot, the EFA yielded five factors based on parallel analysis.
We plotted the factor loadings of each factor in the Pilot against those in Study 1 to investigate their correspondence (See Figure A3.1).
In general, individual items largely loaded on the same factors, and the sizes of their loadings were also comparable.
The items from the CHAOS were found to be most unstable, with many showing a loading < .32 in one of the two studies.

```{r}
#| label: figureA3.1
#| dpi: 600
#| fig.width: 6
#| fig.height: 4
#| fig-cap: | 
#|   **Figure A3.1.** Comparison of factor loadings of unpredictability items in the Pilot and Study 1 (Part 1). 
study1_efa_fig 
```

### Bivariate correlations between future orientation and impulsivity with attention tasks 

Table A3.2 shows bivariate correlations between self-reported depression, impulsivity, future orientation, and SES with each of the Flanker SSP parameters and the Global-Local drift rate difference.
Participants who reported more depressive symptoms had a lower strength of perceptual input.
Participants who reported more impulsivity had a lower strength of perceptual input, higher interference, as well as a more holistic processing style.
Participants who were more future oriented had a higher strength of perceptual input and a more detail-oriented processing style, without an association with interference.

```{r}
#| tab.id: tableA3.3
#| results: markup
supp_cor_table |> 
  flextable::compose(
    i = 1, j = 1,
    as_paragraph(as_b("Table A3.3. "), "Bivariate correlations between exploratory measures and SSP parameters."),
    part = "header"
  ) |>
  padding(
    i = 1:10,
    j = 1:11,
    padding.top = 3,
    padding.bottom = 3,
    part = "body"
  ) |> 
  padding(
    i = 1:2,
    j = 1:11,
    padding.top = 3,
    padding.bottom = 3,
    part = "header"
  ) |> 
  padding(
    i = 1,
    j = 1:11,
    padding.top = 3,
    padding.bottom = 3,
    part = "footer"
  )
```

## Section 3. Model fit

### Pilot

**Cueing and Change Detection Task.** In our initial, preregistered approach, DDM models for the Cueing and Change Detection Task were fit with the fast-dm-30 software [@voss_2015] using maximum likelihood (ML) estimation.
For both tasks, we started out with a model that freely estimated all parameters, and then fit additional models with an increasing number of constrained parameters.
We compared model fit using the Bayesian information criterion (BIC), for which smaller values indicate better fit.
For the Change Detection Task, the most simple model provided the best fit.
This model freely estimated the drift rate, non-decision time, and boundary separation, and fixed all other parameters.

For the Cued Attention Task, three models provided comparable model fit.
However, all three models showed estimation problems, especially with regard to the boundary separation.
Specifically, boundary separation estimates for several participants ended up at an upper boundary of 10, indicating that they were not recovered well (see Figure A3.2).
Based on subsequent external input, we fit an additional model using Kolmogorov-Smirnov (KS) estimation instead of ML estimation, additionally estimating the inter-trial variability parameter of the non-decision time.
This improved parameter estimation (see Figure A3.4).

```{r}
#| label: figureA3.2
#| dpi: 600
#| fig.width: 6
#| fig.height: 3
#| fig-cap: | 
#|   **Figure A3.2.** Distributions of Drift Diffusion Model parameters for the Cued Attention Task using Maximum likelihood estimation.
cueing_DDM_results_mod8 |> select(starts_with("cueing"), -cueing_ml_fit) |> 
     rename(
         "a" = cueing_ml_a,
         "v - cued" = cueing_cued_ml_v,
         "v - neutral" = cueing_neutral_ml_v,
         "t - cued" = cueing_cued_ml_t0,
         "t - neutral" = cueing_neutral_ml_t0,
     ) |> 
     pivot_longer(everything(), names_to = "parameter", values_to = "Estimate") |> 
     ggplot(aes(Estimate)) +
     geom_histogram() +
     facet_wrap(~parameter, scales = 'free') +
     theme_classic()
```

```{r}
#| label: figureA3.3
#| dpi: 600
#| fig.height: 3
#| fig.width: 6
#| fig-cap: | 
#|   **Figure A3.3.** Distributions of Drift Diffusion Model parameters for the Cued Attention Task using Kolmogorov-Smirnov estimation.
cueing_DDM_results_mod9 |> 
  select(starts_with("cueing"), -cueing_ks_fit) |> 
  rename(
    "a" = cueing_ks_a,
    "v - cued" = cueing_cued_ks_v,
    "v - neutral" = cueing_neutral_ks_v,
    "t - cued" = cueing_cued_ks_t0,
    "t - neutral" = cueing_neutral_ks_t0,
  ) |> 
  pivot_longer(everything(), names_to = "parameter", values_to = "Estimate") |> 
  ggplot(aes(Estimate)) +
  geom_histogram() +
  facet_wrap(~parameter, scales = 'free') +
  theme_classic()
```

Finally, we switched to estimation using Hierarchical Bayesian DDM (HDDM) for our final analyses.
The main reason for this step was that although KS estimation seemed to work well, we had fewer trials than is typically recommended for this estimation technique [@lerche_2017].
An advantage of HDDM is that it uses group-level estimates to inform and constrain individual-level estimates.
This is especially useful in cases such as ours, where we have a large sample size but relatively few trials per participant.

The HDDM models were fit using the *runjags* package [@denwood_2016], using code from @johnson_2017.
All models were fit using three Markov Chain Monte Carlo (MCMC) chains.
Each of these chains started with 2,000 burn-in samples, followed by 10,000 additional samples.
To decrease the total size of the model, every 10th sample was retained, resulting in a posterior sample of 3,000 samples.

Model convergence was assessed (1) by visually inspecting the traces, which should not contain any drifts or large jumps (see Figure A3.4 and Figure A3.7); (2) through simulation. Specifically, we used each participant's DDM estimates to simulate 100 RT and accuracy estimates (per condition). The distributions of the participant's true RTs and their simulated RTs were assessed through bivariate correlations at the 25th, 50th and 75th percentile (See Figure A3.5 and Figure A3.8).
We made the same comparison for mean accuracy levels (See Figure A3.6 and Figure A3.9).

```{r}
#| label: figureA3.4
#| dpi: 600
#| fig.width: 6
#| fig.height: 3
#| fig-cap: | 
#|   **Figure A3.4. ** Chain convergence for the Hierarchical Bayesion Drift Diffusion Model for the Cued Attention Task. Plots should resemble a 'fat, hairy catterpillar'.
pilot_traces_cueing
```

```{r}
#| label: figureA3.5
#| dpi: 600
#| fig.width: 6
#| fig.height: 4
#| fig-cap: | 
#|   **Figure A3.5.** Drift Diffusion parameter recovery for the Cued Attention Task comparing simulated and recovered response times at the 25th, 50th and 75th percentile of response times.
pilot_recov_rt_cueing
```

```{r}
#| label: figureA3.6
#| dpi: 600
#| fig.width: 6
#| fig.height: 2
#| fig-cap: | 
#|   **Figure A3.6.** Drift Diffusion parameter recovery for the Cued Attention Task comparing simulated and recovered accuracy rates.
pilot_recov_acc_cueing
```

```{r}
#| label: figureA3.7
#| dpi: 600
#| fig.width: 6
#| fig.height: 1.5
#| fig-cap: | 
#|   **Figure A3.7.** Chain convergence for the Hierarchical Bayesion Drift Diffusion Model for the Change Detection Task. Plots should resemble a 'fat, hairy catterpillar'.
pilot_traces_change
```

```{r}
#| label: figureA3.8
#| dpi: 600
#| fig.width: 6
#| fig.height: 2
#| fig-cap: | 
#|   **Figure A3.8.** Drift Diffusion parameter recovery for the Change Detection Task comparing simulated and recovered response times at the 25th, 50th and 75th percentile of response times.
pilot_recov_rt_change
```

```{r}
#| label: figureA3.9
#| dpi: 600
#| fig.width: 4
#| fig.height: 2
#| fig-cap: | 
#|   **Figure A3.9.** Drift Diffusion parameter recovery for the Change Detection Task comparing simulated and recovered accuracy rates.
pilot_recov_acc_change
```

**Flanker.** To fit the SSP model to the Flanker data, we followed recommendations by @grange_2016.
First, we searched for the optimal set of starting values.
For each participant, we used 50 sets of starting parameters with a variance of 20 for each, simulating 1,000 trials.
After finding the optimal starting values, we fit the final model based on 50,000 simulated trials.
Model fit was assessed through simulation.
For each participant, we simulated 50,000 trials.
We then calculated correlations between observed and simulated RTs at the 25th, 50th, and 75th percentile, as well as between observed and simulated mean accuracy.
As can be seen in Figure A3.10 and Figure A3.11, we observed high agreement between observed and simulated RTs and accuracy rates.

```{r}
#| label: figureA3.10
#| dpi: 600
#| fig.width: 6
#| fig.height: 4
#| fig-cap: | 
#|   **Figure A3.10.** Drift Diffusion parameter recovery for the Flanker comparing simulated and recovered response times at the 25th, 50th and 75th percentile of response times.
qq_data_flanker <- left_join(predicted_quantiles_flanker, observed_quantiles_flanker)

qq_flanker_rt <- ggplot(qq_data_flanker) +
  geom_point(aes(quan_rt_obs, quan_rt_pred)) +
  geom_abline(slope = 1, intercept = 0) +
  facet_grid(congruency~quantile) +
  labs(
    x = "\nObserved RT",
    y = "Predicted RT\n",
    title = "Flanker Task"
  ) +
  theme_classic()

qq_flanker_rt
```

```{r}
#| label: figureA3.11
#| dpi: 600
#| fig.width: 6
#| fig.height: 4
#| fig-cap: | 
#|   **Figure A3.11.** Drift Diffusion parameter recovery for the Flanker comparing simulated and recovered accuracy rates.
ggplot(qq_data_flanker) +
  geom_point(aes(prop_acc_obs, prop_acc_pred)) +
  geom_abline(slope = 1, intercept = 0) +
  facet_grid(congruency~quantile) +
  expand_limits(x = 0, y = 0) +
  labs(
    x = "\nObserved Acc",
    y = "Predicted Acc\n"
  ) +
  theme_classic()
```

### Study 1

Model fit of the Flanker was done the same as in the Pilot.
Figure A3.12 and Figure A3.13 show the model fit based on simulated data.
We found good model fit across all three conditions, both for RTs as well as accuracy rates.

```{r}
#| label: figureA3.12
#| dpi: 600
#| fig.width: 6
#| fig.height: 9
#| fig-cap: | 
#|   **Figure A3.12.** Drift Diffusion parameter recovery for the Flanker comparing simulated and recovered response times at the 25th, 50th and 75th percentile of response times across the standard, enhanced, and degraded condition.
study1_ssp_fit_rt
```

```{r}
#| label: figureA3.13
#| dpi: 600
#| fig.width: 6
#| fig.height: 4
#| fig-cap: | 
#|   **Figure A3.13.** Drift Diffusion parameter recovery for the Flanker comparing simulated and recovered accuracy rates across the standard, enhanced, and degraded condition.
study1_ssp_fit_acc
```

### Study 2.

**Flanker**. Model fit of the Flanker was done the same as in the Pilot and Study 1.
Figure A3.14 and Figure A3.15 show the model fit based on simulated data.
We found good model fit, both for RTs as well as accuracy rates.

```{r}
#| label: figureA3.14
#| dpi: 600
#| fig.width: 6
#| fig.height: 4
#| fig-cap: | 
#|   **Figure A3.14.** Drift Diffusion parameter recovery for the Flanker comparing simulated and recovered response times at the 25th, 50th and 75th percentile of response times.
study2_ssp_fit_rt
```

```{r}
#| label: figureA3.15
#| dpi: 600
#| fig.width: 4
#| fig.height: 2
#| fig-cap: | 
#|   **Figure A3.15.** Drift Diffusion parameter recovery for the Flanker comparing simulated and recovered accuracy rates.
study2_ssp_fit_acc
```

## Section 4. Deviations from preregistrations

In this section, we provide a numbered overview of the deviations from the preregistration in each study.

### Pilot

1. *DDM estimation using Hierarchical Bayesian DDM instead of Maximum Likelihood estimation.* The rational for this change is explained in more detail in section 3.

2. *Focus on Flanker Interference instead of separate attention parameters.* The SSP model provides two parameters representing attentional processes: (1) the initial attention width, and (2) the rate at which attention shrinks towards the central target. 
We had initially planned to analyze both parameters separately.
However, after analyzing the data from Study 1, we realized that the estimates of these two parameters separately were very unstable.
We noticed this when plotting the within-person estimates between conditions (standard, enhanced, and degraded) against each other.
Figure A3.16 provides an overview of these correlations for attentional width, shrinking rate, interference, and, for illustrative purposes, the RT difference score.
We consider the comparison between the standard and enhanced condition the most informative, as the stimuli in these conditions were most similar.
The within-person correlations between conditions of attentional width and shrinking were very low.
However, the correlations were substantially higher for interference (which even outperformed the standard RT difference scores, as typically used in traditional assessments).
Thus, we decided to use the Interference estimate in our analyses across all studies.

```{r}
#| label: figureA3.16
#| fig-width: 7
#| fig-height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.16. **Within-person bivarate correlations between Flanker conditions in Study 2 for RT differences, attentional width, shrinking rate, and interference.
study1_ssp_cor_plot
```

### Study 1

1. In our preregistration of Study 1, we preregistered four exploratory (hypothesis-generating) aims, which were unrelated to the primary (hypothesis-driven) aims described in the main manuscript. These were: (1) Investigating the factor structure of unpredictability measures and comparing it to the structure found in the Pilot; (2) Exploring the role of state anxiety, hunger, and sleep deprivation as potential moderators of the relationship between adversity and attention performance; (3) Exploring bivariate correlations between measures of adversity, attention, and measures of temporal orientation; (4) Explore the correlation between current depressive symptoms and retrospective measures of adversity. The results of aim 1 are described in Section 2. Results of aim 2-4 are described in Section 2. 

### Study 2

1. *Global-Local performance.* In the original preregistration, we specified that we would exclude participants who performed at chance on either the Flanker Task or the Global-Local Task, which was defined as an accuracy of 59.4% or lower.
However, initial inspections of the Global-Local Task data showed that a substantial part of the sample did not reach this cut-off, suggesting that the task was more difficult than anticipated.
Thus, we developed a more fine-grained approach (described below) in an attempt to distinguish between 1) participants who did not understand the task and 2) participants who understood the task, but found it difficult to perform well. 
Given the assumptions of DDM, the first group would have to be excluded because they likely did not go through a process of information accumulation.
However, the model should be able to adequately fit the data of the second group.

The amended analysis approach for the Global-Local Task looked as follows: (1) Fit the data to the cleaned data of the full sample, including participants who performed at or below chance level (i.e., after trial-level exclusions but before case-wise exclusions); (2) Based on recovered parameter estimates for each participant, simulate the same number of trials (reaction times and accuracy) using the `RWiener` package, separately for Global and Local trials. (3) For each participant, calculate the 25th, 50th and 75th quantile of both their real RTs and the simulated RTs. 
In addition, we calculate mean accuracies based on the real and simulated data. (4) Compute standardized residuals between the real and simulated data for RTs at each quantile and for accuracy.
In case of good fit, the residual should be close to zero. (5) Exclude the data of participants with any standardized residual > 3.2 SD.

2. *Multiverse analysis.* In the preregistration, we planned to include three variables as covariates that were previously featured as arbitrary exclusion decisions in the multiverse specification: 1) whether or not participants rescaled the screen; 2) whether or not participants exited fullscreen mode at some point during the tasks; 3) Whether or not participants experienced interruptions during the tasks.
Our reasoning was that these three factors were consistently found to have a large impact on model results.
However, we realized later on that adding these factors as covariates was not a good approach from a causal inference standpoint.
That is, it is more likely that each of these factors added random noise to our estimates than that they had a causal effect on the outcome.
Therefore, we decided instead to include these factors as arbitrary decisions in the multiverse analyses, similarly as the previous two studies.
This allowed for a coherent assessment of influential factors across all three experiments.

## Section 5. Multiverse analysis.

In this section, we provide additional results of the multiverse analyses.
Specifically, we report (1) the distributions of *p*-values across the multiverses and (2) influential data cleaning decisions.

### Pilot 

Figure A3.17 and Figure A3.18 present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Table 3 in the main text.

```{r}
#| label: figureA3.17
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.17.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Cued Attention Task. Panel B: Change Detection Task. Panel C: Flanker Task.
(
  (pilot_prim_lmer_pvalues_plot$cueing_rt + labs(title = "Raw response time", tag = "A", y = "") + theme_classic()) + 
    (pilot_prim_lmer_pvalues_plot$cueing_hddm_v + labs(title = "Drift rate", y = "") + theme_classic()) + 
    (pilot_prim_lm_pvalues_plot$cueing_fixed_hddm_a + labs(title = "Boundary separation", y = "") + theme_classic()) + 
    (pilot_prim_lmer_pvalues_plot$cueing_hddm_t + labs(title = "Non-decision time", y = "") + theme_classic())
) /
  (
    (pilot_prim_lm_pvalues_plot$rt_change + labs(title = "Raw response time", tag = "B", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$change_hddm_v + labs(title = "Drift rate", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$change_hddm_a + labs(title = "Boundary separation", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$change_hddm_t + labs(title = "Non-decision time", y = "") + theme_classic())
  ) /
  (
    (pilot_prim_lmer_pvalues_plot$flanker_rt + labs(title = "Raw response time", tag = "C", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$flanker_ssp_p + labs(title = "Perceptual input", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$flanker_ssp_a + labs(title = "Boundary separation", y = "") + theme_classic()) +
      (pilot_prim_lm_pvalues_plot$flanker_ssp_t + labs(title = "Non-decision time", y = "") + theme_classic())
  ) 
```

```{r}
#| include: false
#| echo: false
f18_p1 <- pilot_prim_lmer_variance_plot$cueing_rt + labs(title = "Raw response time", tag = "A", y = "", fill = "")
f18_p2 <- pilot_prim_lmer_variance_plot$cueing_hddm_v + labs(title = "Drift rate", y = "") + guides(fill = "none")
f18_p3 <- pilot_prim_lm_variance_plot$cueing_fixed_hddm_a + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f18_p4 <- pilot_prim_lmer_variance_plot$cueing_hddm_t + labs(title = "Non-decision time", y = "") + guides(fill = "none")

f18_p5 <- pilot_prim_lm_variance_plot$rt_change + labs(title = "Raw response time", tag = "B", y = "") + guides(fill = "none") 
f18_p6 <- pilot_prim_lm_variance_plot$change_hddm_v + labs(title = "Drift rate", y = "") + guides(fill = "none") 
f18_p7 <- pilot_prim_lm_variance_plot$change_hddm_a + labs(title = "Boundary separation", y = "") + guides(fill = "none")
f18_p8 <- pilot_prim_lm_variance_plot$change_hddm_t + labs(title = "Non-decision time", y = "") + guides(fill = "none") 

f18_p9 <- pilot_prim_lmer_variance_plot$flanker_rt + labs(title = "Raw response time", tag = "C", y = "") + guides(fill = "none")
f18_p10 <- pilot_prim_lm_variance_plot$flanker_ssp_p + labs(title = "Perceptual input", y = "") + guides(fill = "none") 
f18_p11 <- pilot_prim_lm_variance_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + guides(fill = "none") 
f18_p12 <- pilot_prim_lm_variance_plot$flanker_ssp_a + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f18_p13 <- pilot_prim_lm_variance_plot$flanker_ssp_t + labs(title = "Non-decision time", y = "") + guides(fill = "none")

align_patches(f18_p1,f18_p2,f18_p3,f18_p4,f18_p5,f18_p6,f18_p7,f18_p8,f18_p9,f18_p10,f18_p11,f18_p12,f18_p13)
```

```{r}
#| label: figureA3.18
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.18.** Multiverse explained variance of each data cleaning decision belonging to the analyses reported in Table 3 in the main text. Panel A: Cued Attention Task. Panel B: Change Detection Task. Panel C: Flanker Task.
final_plot_S18 <- 
  (f18_p1+f18_p2+f18_p3+f18_p4 + plot_layout(ncol = 3)) /
  (f18_p5+f18_p6+f18_p7+f18_p8 + plot_layout(ncol = 3)) /
  (f18_p9+f18_p10+f18_p11+f18_p12+f18_p13 + plot_layout(ncol = 3)) + 
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S18

```

### Study 1

Figure A3.19 and Figure A3.20 present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Table 4 in the main text.

```{r}
#| label: figureA3.19
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.19.** Multiverse p-value distributions belonging to the analyses reported in Table 4 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Analyses involving violence exposure (hypothesis-driven). Panel B: Analyses involving unpredictability (exploratory).
(
  (study1_prim_ssp_pvalues_plot_study1$rt_diff + labs(title = "RT difference", tag = "A", y = "") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + theme_classic()) +
    (study1_prim_ssp_pvalues_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + theme_classic())
) /
  (
    (study1_expl_ssp_pvalues_plot_study1$rt_diff + labs(title = "RT difference", tag = "B", y = "") + theme_classic()) + 
      (study1_expl_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + theme_classic()) + 
      (study1_expl_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "") + theme_classic()) + 
      (study1_expl_ssp_pvalues_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + theme_classic()) +
      (study1_expl_ssp_pvalues_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + theme_classic())
  )
```

```{r}
#| include: false
#| echo: false
f20_p1 <- study1_prim_ssp_variance_plot_study1$rt_diff + labs(title = "RT difference", tag = "A", y = "", fill = "")
f20_p2 <- study1_prim_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none") 
f20_p3 <- study1_prim_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f20_p4 <- study1_prim_ssp_variance_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f20_p5 <- study1_prim_ssp_variance_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 

f20_p6 <- study1_expl_ssp_variance_plot_study1$rt_diff + labs(title = "RT difference", tag = "B", y = "") + guides(fill = "none") 
f20_p7 <- study1_expl_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none")
f20_p8 <- study1_expl_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")
f20_p9 <- study1_expl_ssp_variance_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f20_p10 <- study1_expl_ssp_variance_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 


align_patches(f20_p1,f20_p2,f20_p3,f20_p4,f20_p5,f20_p6,f20_p7,f20_p8,f20_p9,f20_p10)
```

```{r}
#| label: figureA3.20
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.20.** Multiverse explained variance of each data cleaning decision belonging to the analyses reported in Table 4 in the main text. Panel A: Analyses involving violence exposure (hypothesis-driven). Panel B: Analyses involving unpredictability (exploratory).
final_plot_S20 <- 
  (f20_p1+f20_p2+f20_p3+f20_p4+f20_p5 + plot_layout(ncol = 3)) /
  (f20_p6+f20_p7+f20_p8+f20_p9+f20_p10 + plot_layout(ncol = 3)) +
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S20

```

Figures A3.21-A24 present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Table 5 in the main text.

```{r}
#| label: figureA3.21
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.21.** Multiverse p-value distributions belonging to the interaction effects involving violence exposure reported in Table 5 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
(
  (study1_prim_ssp_enh_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "A", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_enh_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_enh_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_enh_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_prim_ssp_enh_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
) /
  (
    (study1_prim_ssp_deg_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "B", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_deg_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_deg_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_deg_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_prim_ssp_deg_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
  )
```

```{r}
#| include: false
#| echo: false
f22_p1 <- study1_prim_ssp_enh_variance_plot$rt_diff + labs(title = "RT difference", tag = "A", y = "", fill = "")
f22_p2 <- study1_prim_ssp_enh_variance_plot$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none") 
f22_p3 <- study1_prim_ssp_enh_variance_plot$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f22_p4 <- study1_prim_ssp_enh_variance_plot$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f22_p5 <- study1_prim_ssp_enh_variance_plot$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 

f22_p6 <- study1_prim_ssp_deg_variance_plot$rt_diff + labs(title = "RT difference", tag = "B", y = "") + guides(fill = "none") 
f22_p7 <- study1_prim_ssp_deg_variance_plot$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none")
f22_p8 <- study1_prim_ssp_deg_variance_plot$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f22_p9 <- study1_prim_ssp_deg_variance_plot$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f22_p10 <- study1_prim_ssp_deg_variance_plot$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none")


align_patches(f22_p1,f22_p2,f22_p3,f22_p4,f22_p5,f22_p6,f22_p7,f22_p8,f22_p9,f22_p10)
```

```{r}
#| label: figureA3.22
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.22.** Multiverse explained variance of each data cleaning decision belonging to the interaction effects involving violence exposure reported in Table 5 in the main text. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
final_plot_S22 <- 
  (f22_p1+f22_p2+f22_p3+f22_p4+f22_p5 + plot_layout(ncol = 3)) /
  (f22_p6+f22_p7+f22_p8+f22_p9+f22_p10 + plot_layout(ncol = 3)) /
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S22

```

```{r}
#| label: figureA3.23
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.23.** Multiverse p-value distributions belonging to the interaction effects involving unpredictability reported in Table 5 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
(
  (study1_expl_ssp_enh_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "A", x = "p", y = "")) + theme_classic() + 
    (study1_expl_ssp_enh_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_enh_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_enh_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_expl_ssp_enh_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
) /
  (
    (study1_expl_ssp_deg_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "B", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_deg_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_deg_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_deg_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_expl_ssp_deg_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
  )
```

```{r}
#| include: false
#| echo: false

f24_p1 <- study1_expl_ssp_enh_variance_plot$rt_diff  + theme_classic()
f24_p2 <- study1_expl_ssp_enh_variance_plot$p_flanker + theme_classic()
f24_p3 <- study1_expl_ssp_enh_variance_plot$interference_flanker + theme_classic()
f24_p4 <- study1_expl_ssp_enh_variance_plot$a_flanker + theme_classic()
f24_p5 <- study1_expl_ssp_enh_variance_plot$t0_flanker + theme_classic()

f24_p6 <- study1_expl_ssp_deg_variance_plot$rt_diff + theme_classic()
f24_p7 <- study1_expl_ssp_deg_variance_plot$p_flanker + theme_classic()
f24_p8 <- study1_expl_ssp_deg_variance_plot$interference_flanker + theme_classic()
f24_p9 <- study1_expl_ssp_deg_variance_plot$a_flanker + theme_classic()
f24_p10 <- study1_expl_ssp_deg_variance_plot$t0_flanker + theme_classic()


f24_p1 <- f24_p1 + labs(title = "RT difference", tag = "A", fill = "")
f24_p2 <- f24_p2 + labs(title = "Perceptual input") + guides(fill = "none")
f24_p3 <- f24_p3 + labs(title = "Interference") + guides(fill = "none")
f24_p4 <- f24_p4 + labs(title = "Boundary separation") + guides(fill = "none")
f24_p5 <- f24_p5 + labs(title = "Non-decision time") + guides(fill = "none")

f24_p6 <- f24_p6 + labs(title = "RT difference", tag = "B") + guides(fill = "none") 
f24_p7 <- f24_p7 + labs(title = "Perceptual input") + guides(fill = "none")
f24_p8 <- f24_p8 + labs(title = "Interference") + guides(fill = "none")
f24_p9 <- f24_p9 + labs(title = "Boundary separation") + guides(fill = "none")
f24_p10 <- f24_p10 + labs(title = "Non-decision time") + guides(fill = "none") 


align_patches(f24_p1,f24_p2,f24_p3,f24_p4,f24_p5,f24_p6,f24_p7,f24_p8,f24_p9,f24_p10)
```

```{r}
#| label: figureA3.24
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.24.** Multiverse explained variance of each data cleaning decision belonging to the interaction effects involving unpredictability reported in Table 5 in the main text. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
final_plot_S24 <- 
  (f24_p1+f24_p2+f24_p3+f24_p4+f24_p5 + plot_layout(ncol = 3)) /
  (f24_p6+f24_p7+f24_p8+f24_p9+f24_p10 + plot_layout(ncol = 3)) /
  plot_layout(guides = "collect") &  theme(legend.position='bottom', axis.text.y = element_blank())

final_plot_S24

```

### Study 2

Figure A3.25 and Figure A3.26 present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Figure 2 in the main text.

```{r}
#| label: figureA3.25
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.25.** Multiverse p-value distributions belonging to the associations between violence exposure with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 2 in the main text. 
(
  (pilot_prim_lm_pvalues_plot$flanker_ssp_p + labs(title = "Perceptual input", tag = "Pilot", y = "", x = "p") + theme_classic()) + 
    (pilot_prim_lm_pvalues_plot$flanker_ssp_interference + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
) /
  (
    (study1_prim_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "", x = "p") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
  ) /
  (
    (study2_prim_aim1_pvalues_plot_study2$p_flanker.vio_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + theme_classic()) + 
    (study2_prim_aim1_pvalues_plot_study2$interference_flanker.vio_comp + labs(title = "Interference", y = "") + theme_classic()) 
  ) /
  (
    (study2_aim1_ssp_pooled_pvalues_plot$vio_comp_p_flanker + labs(title = "Perceptual input", tag = "Pooled", y = "") + theme_classic()) + 
    (study2_aim1_ssp_pooled_pvalues_plot$vio_comp_interference_flanker + labs(title = "Interference", y = "") + theme_classic()) 
  )
```

```{r}
#| label: figureA3.26
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.26.** Multiverse explained variance of each data cleaning decision belonging to the associations between violence exposure with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 2 in the main text. 
(
  (pilot_prim_lm_variance_plot$flanker_ssp_p + labs(title = "Perceptual input", tag = "Pilot", fill = "", y = "")) + 
    (pilot_prim_lm_variance_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + guides(fill = "none")) 
) /
  (
    (study1_prim_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "") + guides(fill = "none")) + 
    (study1_prim_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot_study2$p_flanker.vio_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot_study2$interference_flanker.vio_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot$p_flanker.vio_comp + labs(title = "Perceptual input", tag = "Pooled", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot$interference_flanker.vio_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) + plot_layout(guides = "collect") & theme(legend.position='bottom')
```

Figure A3.27 and Figure A3.28 present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Figure 3 in the main text.

```{r}
#| label: figureA3.27
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.27.** Multiverse p-value distributions belonging to the associations between unpredictability with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 3 in the main text. 
(
  (pilot_expl_lm_pvalues_plot$flanker_ssp_p + labs(title = "Perceptual input", tag = "Pilot", y = "", x = "p") + theme_classic()) + 
    (pilot_expl_lm_pvalues_plot$flanker_ssp_interference + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
) /
  (
    (study1_expl_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "", x = "p") + theme_classic()) + 
    (study1_expl_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
  ) /
  (
    (study2_prim_aim1_pvalues_plot_study2$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + theme_classic()) + 
    (study2_prim_aim1_pvalues_plot_study2$interference_flanker.unp_comp + labs(title = "Interference", y = "") + theme_classic()) 
  ) /
  (
    (study2_prim_aim1_pvalues_plot$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Pooled", y = "") + theme_classic()) + 
    (study2_prim_aim1_pvalues_plot$interference_flanker.unp_comp + labs(title = "Interference", y = "") + theme_classic()) 
  )
```

```{r}
#| label: figureA3.28
#| fig.width: 6
#| fig.height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure A3.28.** Multiverse explained variance of each data cleaning decision belonging to the associations between unpredictability with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 3 in the main text. 
(
  (pilot_expl_lm_variance_plot$flanker_ssp_p + labs(title = "Perceptual input", fill = "", tag = "Pilot", y = "")) + 
    (pilot_expl_lm_variance_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + guides(fill = "none")) 
) /
  (
    (study1_expl_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "") + guides(fill = "none")) + 
    (study1_expl_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot_study2$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot_study2$interference_flanker.unp_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Pooled", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot$interference_flanker.unp_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) + plot_layout(guides = "collect") & theme(legend.position='bottom')
```

```{=typst}
#pagebreak()
```
